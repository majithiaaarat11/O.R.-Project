{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis Using Naive Bayes Classifier\n",
    "\n",
    "<img src=\"Intro2.PNG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "Let's have a look at our training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>SentimentText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>124984</th>\n",
       "      <td>0</td>\n",
       "      <td>kid 50's 60's anything connected Disney defini...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124985</th>\n",
       "      <td>1</td>\n",
       "      <td>course reading review seen film already. 'Raja...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124986</th>\n",
       "      <td>0</td>\n",
       "      <td>read \"There's Girl Soup\" came Peter Sellers's ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124987</th>\n",
       "      <td>0</td>\n",
       "      <td>film quite boring. snippets naked flesh tossed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124988</th>\n",
       "      <td>1</td>\n",
       "      <td>Although film somewhat filled eighties cheese ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Sentiment                                      SentimentText\n",
       "124984          0  kid 50's 60's anything connected Disney defini...\n",
       "124985          1  course reading review seen film already. 'Raja...\n",
       "124986          0  read \"There's Girl Soup\" came Peter Sellers's ...\n",
       "124987          0  film quite boring. snippets naked flesh tossed...\n",
       "124988          1  Although film somewhat filled eighties cheese ..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"data.csv\")\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *\"SentimentText\"* column has reviews/tweets and the *\"Sentiment\"* column has the corresponding sentiment value, \"0\" is negative and \"1\" is positive.\n",
    "\n",
    "## Data pre-processing\n",
    "\n",
    "Let's prepare our data for the model.\n",
    "\n",
    "The **tfidfvetorizer** is useful for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "stopset = set(stopwords.words('english'))\n",
    "vectorizer = TfidfVectorizer(use_idf = True, lowercase = True, strip_accents = 'ascii', stop_words = stopset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *tfidfvectorizer* mainly does two things:\n",
    "1. For unique word in each document, count how many times it shows up in that document. That's **\"Term Frequency” (TF)**\n",
    "2. Then, take that unique word and count how many times it shows up in all documents. That's **“Document Frequency” (DF)**\n",
    "(to keep the range reasonble, we use **log** of this frequency. That's **\"Inverse Document Frequency\" (IDF)**)\n",
    "\n",
    "**Stopwords** are words that are common and do not provide much information about the label of the text. \n",
    "For example, \"the\", \"a\", \"of\", etc.\n",
    "\n",
    "## Fitting the model\n",
    "\n",
    "Here the target variable will be the *Sentiment* using the *SentimentText *."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df.Sentiment\n",
    "\n",
    "X = vectorizer.fit_transform(df.SentimentText) # Fitting and transforming using the vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the **naive_bayes** class from the **Sci-kit learn** module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready\n"
     ]
    }
   ],
   "source": [
    "from sklearn import naive_bayes\n",
    "\n",
    "clf=naive_bayes.MultinomialNB()\n",
    "clf.fit(X,y)\n",
    "print(\"Ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classifier is ready!\n",
    "Let's try some reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "code_folding": [
     6
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Press Enter when you are ready to write a review: \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19848fc4ca10411e939025f46bb7d01d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Text(value='', description='Review'), Output()), _dom_classes=('widget-interact',))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display                               \n",
    "from ipywidgets import interactive\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "\n",
    "def ren(Review):\n",
    "    review_array = np.array([Review])\n",
    "    review_vector = vectorizer.transform(review_array)\n",
    "    if(Review==\"\"):\n",
    "        print(\"Write something!\")\n",
    "    elif(clf.predict(review_vector)==0):\n",
    "        plt.imshow(mpimg.imread('t_d.jpg'))\n",
    "        plt.axis('off')\n",
    "    else:\n",
    "        plt.imshow(mpimg.imread('t_u.jpg'))\n",
    "        plt.axis('off')\n",
    "\n",
    "re = input(\"Press Enter when you are ready to write a review: \")\n",
    "\n",
    "inter = interactive(ren,\n",
    "                   Review = re)\n",
    "display(inter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis for tweets\n",
    "\n",
    "We can use this classifier for a chunk of reviews and opinions simultaneously.\n",
    "\n",
    "Let's jump to the place which is just right for us!\n",
    "\n",
    "<img src=\"twitter-logo.png\">\n",
    "\n",
    "Twitter is like a constantly updating dataset with public opinions on a topic.\n",
    "\n",
    "---\n",
    "\n",
    "For accessing the **twitter api** we are using the module **tweepy**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Authorization set-up for the api."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_key = 'IFJlqnamXmKdoe1VW0oLjk3UP'\n",
    "consumer_secret = 'zLXq4gnaQ8o3Qs1gejCbWdx82FghXESfgRiiquDztWCpVYDNui'\n",
    "\n",
    "access_token = '612553252-brPdasq0Ho9LOaPtc77ho6PvvsApC2oonOmFVWaz'\n",
    "access_token_secret = '6zropkmLNLcEye7jFOzE5ctuic0oDplZHlhokfbzmuRW1'\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token,access_token_secret)\n",
    "\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "code_folding": [
     30
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Press Enter when you are ready to search\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fec505d7dd124d1c91bfb2716ae8b133",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Text(value='', description='Search'), Output()), _dom_classes=('widget-interact',))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from textblob import TextBlob\n",
    "\n",
    "\n",
    "def tweet_analyzer(Search):\n",
    "    p = 0\n",
    "    n = 0\n",
    "    l = 0\n",
    "    if(Search==\"\"):\n",
    "        print(\"Search a hashtag or a topic\")\n",
    "    else:\n",
    "        public_tweets = api.search(q = Search,count = 20, lang = \"en\" )\n",
    "        for tweet in public_tweets:\n",
    "            print(tweet.text)\n",
    "            analysis = TextBlob(tweet.text)\n",
    "            if analysis.sentiment.polarity > 0:\n",
    "                p=p+1\n",
    "#                p.append(1)\n",
    "                print(\"1\")\n",
    "            elif analysis.sentiment.polarity == 0:\n",
    "                l=l+1\n",
    "#                l.append(1)\n",
    "                print(\"0\")\n",
    "            else:\n",
    "                n=n+1\n",
    "#                n.append(1)\n",
    "                print(\"-1\")\n",
    "            print(\"##############################################\")\n",
    "\n",
    "se = input(\"Press Enter when you are ready to search\")\n",
    "\n",
    "inter_tweet = interactive(tweet_analyzer,\n",
    "                   Search = se)\n",
    "display(inter_tweet)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
